{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55160c98-98eb-4993-8a01-3d151ea19479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from simulator.model.robust_mse import RobustBidMSE\n",
    "from simulator.model.simple import SimpleBid\n",
    "from simulator.simulation.utils_visualization import plot_metric_with_error_CTR\n",
    "from simulator.validation.check_results import autobidder_check\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4682594f",
   "metadata": {},
   "source": [
    "# This notebook provides a guideline how to simulate and check Robust PID Bidder for all the campaigns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "398bb46f-49cd-4aeb-9392-f57187faee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type = 'MSE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c5d73a-0236-4086-b2db-939ff296c0c0",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae9cec7f-d89a-4412-9abe-830b82895f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_mode = 'FPA'\n",
    "\n",
    "campaigns_path = \"../data/subsample_campaigns.csv\"\n",
    "stats_path = \"../data/subsample_stats.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e6a2a35-6616-4f8b-9a39-12d1cbdec01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_df = pd.read_csv(campaigns_path)\n",
    "stats_df = pd.read_csv(stats_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a806c09-6b92-43f0-9a73-df43d5c968ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>loc_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>campaign_start</th>\n",
       "      <th>campaign_end</th>\n",
       "      <th>auction_budget</th>\n",
       "      <th>microcat_ext</th>\n",
       "      <th>logical_category</th>\n",
       "      <th>region_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.695222e+07</td>\n",
       "      <td>644788.385714</td>\n",
       "      <td>3.515224e+09</td>\n",
       "      <td>5.298478e+08</td>\n",
       "      <td>5.301514e+08</td>\n",
       "      <td>1238.622143</td>\n",
       "      <td>7.844751e+05</td>\n",
       "      <td>2.769286</td>\n",
       "      <td>644358.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.957660e+06</td>\n",
       "      <td>10712.608247</td>\n",
       "      <td>8.250976e+08</td>\n",
       "      <td>3.126187e+05</td>\n",
       "      <td>3.845838e+05</td>\n",
       "      <td>1906.618616</td>\n",
       "      <td>1.013575e+06</td>\n",
       "      <td>1.485689</td>\n",
       "      <td>10649.319309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.986990e+07</td>\n",
       "      <td>621630.000000</td>\n",
       "      <td>1.073987e+09</td>\n",
       "      <td>5.295283e+08</td>\n",
       "      <td>5.297184e+08</td>\n",
       "      <td>75.840000</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>621590.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.307796e+07</td>\n",
       "      <td>637672.500000</td>\n",
       "      <td>2.998627e+09</td>\n",
       "      <td>5.295718e+08</td>\n",
       "      <td>5.298089e+08</td>\n",
       "      <td>228.960000</td>\n",
       "      <td>3.779750e+03</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>637650.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.567955e+07</td>\n",
       "      <td>646410.000000</td>\n",
       "      <td>3.915603e+09</td>\n",
       "      <td>5.297500e+08</td>\n",
       "      <td>5.299637e+08</td>\n",
       "      <td>547.200000</td>\n",
       "      <td>5.533500e+03</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>645790.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.077054e+07</td>\n",
       "      <td>653240.000000</td>\n",
       "      <td>4.063275e+09</td>\n",
       "      <td>5.301044e+08</td>\n",
       "      <td>5.305207e+08</td>\n",
       "      <td>1934.687500</td>\n",
       "      <td>2.096862e+06</td>\n",
       "      <td>3.410000</td>\n",
       "      <td>653240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.776145e+07</td>\n",
       "      <td>661950.000000</td>\n",
       "      <td>4.577216e+09</td>\n",
       "      <td>5.305651e+08</td>\n",
       "      <td>5.308243e+08</td>\n",
       "      <td>13829.760000</td>\n",
       "      <td>2.278193e+06</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>661460.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        campaign_id         loc_id       item_id  campaign_start  \\\n",
       "count  7.000000e+01      70.000000  7.000000e+01    7.000000e+01   \n",
       "mean   7.695222e+07  644788.385714  3.515224e+09    5.298478e+08   \n",
       "std    4.957660e+06   10712.608247  8.250976e+08    3.126187e+05   \n",
       "min    5.986990e+07  621630.000000  1.073987e+09    5.295283e+08   \n",
       "25%    7.307796e+07  637672.500000  2.998627e+09    5.295718e+08   \n",
       "50%    7.567955e+07  646410.000000  3.915603e+09    5.297500e+08   \n",
       "75%    8.077054e+07  653240.000000  4.063275e+09    5.301044e+08   \n",
       "max    8.776145e+07  661950.000000  4.577216e+09    5.305651e+08   \n",
       "\n",
       "       campaign_end  auction_budget  microcat_ext  logical_category  \\\n",
       "count  7.000000e+01       70.000000  7.000000e+01         70.000000   \n",
       "mean   5.301514e+08     1238.622143  7.844751e+05          2.769286   \n",
       "std    3.845838e+05     1906.618616  1.013575e+06          1.485689   \n",
       "min    5.297184e+08       75.840000  2.400000e+01          1.000000   \n",
       "25%    5.298089e+08      228.960000  3.779750e+03          1.380000   \n",
       "50%    5.299637e+08      547.200000  5.533500e+03          2.350000   \n",
       "75%    5.305207e+08     1934.687500  2.096862e+06          3.410000   \n",
       "max    5.308243e+08    13829.760000  2.278193e+06          5.370000   \n",
       "\n",
       "           region_id  \n",
       "count      70.000000  \n",
       "mean   644358.000000  \n",
       "std     10649.319309  \n",
       "min    621590.000000  \n",
       "25%    637650.000000  \n",
       "50%    645790.000000  \n",
       "75%    653240.000000  \n",
       "max    661460.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "campaign_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d892c3e8-b025-4860-8872-8218733f16f1",
   "metadata": {},
   "source": [
    "## Robust LP Bid vs LP Bid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e29feb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Точная реализация генерации шума по Wang & Dong (2023)\n",
    "# на основе формул из статьи с энтропией и логарифмами\n",
    "\n",
    "# Из статьи Wang, X., & Dong, H. (2023):\n",
    "# - Формула (15): H(y*|x*,D) = MI(y*;ω|x*,D) + E(H(y*|x*,ω))\n",
    "# - Формула (17): Ĥ(y*|x*,D) = -∑_c (1/T ∑_t p(y=c|x*,ω̂_t) log(1/T ∑_t p(y=c|x*,ω̂_t)))\n",
    "# - Формула (18): E(Ĥ(y*|x*,ω)) = -1/T ∑_{t,c} p(y=c|x*,ω̂_t) log p(y=c|x*,ω̂_t)\n",
    "# - Формула (19): M̂I(y*;ω|x*,D) = Ĥ(y*|x*,D) - E(Ĥ(y*|x*,ω))\n",
    "# \"\"\"\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from scipy import stats\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# class WangDongCTRNoise:\n",
    "#     \"\"\"\n",
    "#     Генератор шума для CTR на основе точных формул из Wang & Dong (2023)\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, random_state=1337):\n",
    "#         np.random.seed(random_state)\n",
    "#         self.random_state = random_state\n",
    "\n",
    "#     def monte_carlo_dropout_predictions(self, ctr_predicted, T=50, dropout_rate=0.05):\n",
    "#         \"\"\"\n",
    "#         Генерация T предсказаний через Monte Carlo Dropout\n",
    "#         Соответствует процедуре из статьи для получения ω̂_t\n",
    "\n",
    "#         Parameters:\n",
    "#         -----------\n",
    "#         ctr_predicted : array-like\n",
    "#             Базовые предсказания CTR (p(y=1|x*,ω))\n",
    "#         T : int\n",
    "#             Количество MC семплов (как в статье)\n",
    "#         dropout_rate : float\n",
    "#             Dropout rate (рекомендуется 0.05 из экспериментов статьи)\n",
    "\n",
    "#         Returns:\n",
    "#         --------\n",
    "#         mc_predictions : np.array shape (T, N)\n",
    "#             T предсказаний для каждого из N семплов\n",
    "#         \"\"\"\n",
    "#         n_samples = len(ctr_predicted)\n",
    "#         ctr_clipped = np.clip(ctr_predicted, 1e-7, 1-1e-7)  # Избегаем log(0)\n",
    "\n",
    "#         mc_predictions = []\n",
    "\n",
    "#         for t in range(T):\n",
    "#             # Симулируем dropout через модификацию логитов\n",
    "#             # Это приближение к реальному MC Dropout из статьи\n",
    "#             logits = np.log(ctr_clipped / (1 - ctr_clipped))\n",
    "\n",
    "#             # Dropout mask - случайно обнуляем некоторые \"нейроны\"\n",
    "#             dropout_mask = np.random.binomial(1, 1-dropout_rate, n_samples)\n",
    "\n",
    "#             # Добавляем шум, пропорциональный неопределенности\n",
    "#             # Больше шума там, где модель менее уверена (средние значения CTR)\n",
    "#             uncertainty = 4 * ctr_clipped * (1 - ctr_clipped)  # Максимум при CTR=0.5\n",
    "#             noise_std = dropout_rate * uncertainty\n",
    "\n",
    "#             logit_noise = np.random.normal(0, noise_std)\n",
    "#             noisy_logits = logits + logit_noise * dropout_mask\n",
    "\n",
    "#             # Обратное преобразование в вероятности\n",
    "#             mc_ctr = 1 / (1 + np.exp(-noisy_logits))\n",
    "#             mc_predictions.append(mc_ctr)\n",
    "\n",
    "#         return np.array(mc_predictions)\n",
    "\n",
    "#     def calculate_predictive_entropy(self, mc_predictions):\n",
    "#         \"\"\"\n",
    "#         Вычисление предсказательной энтропии Ĥ(y*|x*,D)\n",
    "#         Формула (17) из статьи\n",
    "\n",
    "#         Parameters:\n",
    "#         -----------\n",
    "#         mc_predictions : np.array shape (T, N)\n",
    "#             MC предсказания\n",
    "\n",
    "#         Returns:\n",
    "#         --------\n",
    "#         predictive_entropy : np.array shape (N,)\n",
    "#             Предсказательная энтропия для каждого семпла\n",
    "#         \"\"\"\n",
    "#         T, N = mc_predictions.shape\n",
    "\n",
    "#         # Усредненные предсказания: 1/T ∑_t p(y=c|x*,ω̂_t)\n",
    "#         avg_p1 = np.mean(mc_predictions, axis=0)  # P(y=1)\n",
    "#         avg_p0 = 1 - avg_p1  # P(y=0)\n",
    "\n",
    "#         # Избегаем log(0)\n",
    "#         avg_p1 = np.clip(avg_p1, 1e-7, 1-1e-7)\n",
    "#         avg_p0 = np.clip(avg_p0, 1e-7, 1-1e-7)\n",
    "\n",
    "#         # Формула (17): Ĥ(y*|x*,D) = -∑_c (avg_p_c * log(avg_p_c))\n",
    "#         predictive_entropy = -(avg_p1 * np.log(avg_p1) + avg_p0 * np.log(avg_p0))\n",
    "\n",
    "#         return predictive_entropy\n",
    "\n",
    "#     def calculate_expected_entropy(self, mc_predictions):\n",
    "#         \"\"\"\n",
    "#         Вычисление ожидаемой энтропии E(Ĥ(y*|x*,ω))\n",
    "#         Формула (18) из статьи\n",
    "\n",
    "#         Parameters:\n",
    "#         -----------\n",
    "#         mc_predictions : np.array shape (T, N)\n",
    "#             MC предсказания\n",
    "\n",
    "#         Returns:\n",
    "#         --------\n",
    "#         expected_entropy : np.array shape (N,)\n",
    "#             Ожидаемая энтропия для каждого семпла\n",
    "#         \"\"\"\n",
    "#         T, N = mc_predictions.shape\n",
    "\n",
    "#         # Избегаем log(0)\n",
    "#         mc_predictions_safe = np.clip(mc_predictions, 1e-7, 1-1e-7)\n",
    "#         mc_predictions_0 = 1 - mc_predictions_safe\n",
    "\n",
    "#         # Формула (18): E(Ĥ(y*|x*,ω)) = -1/T ∑_{t,c} p(y=c|x*,ω̂_t) log p(y=c|x*,ω̂_t)\n",
    "#         entropy_per_sample = -(mc_predictions_safe * np.log(mc_predictions_safe) +\n",
    "#                               mc_predictions_0 * np.log(mc_predictions_0))\n",
    "\n",
    "#         expected_entropy = np.mean(entropy_per_sample, axis=0)\n",
    "\n",
    "#         return expected_entropy\n",
    "\n",
    "#     def calculate_mutual_information(self, predictive_entropy, expected_entropy):\n",
    "#         \"\"\"\n",
    "#         Вычисление взаимной информации M̂I(y*;ω|x*,D)\n",
    "#         Формула (19) из статьи\n",
    "\n",
    "#         Parameters:\n",
    "#         -----------\n",
    "#         predictive_entropy : np.array\n",
    "#             Предсказательная энтропия\n",
    "#         expected_entropy : np.array\n",
    "#             Ожидаемая энтропия\n",
    "\n",
    "#         Returns:\n",
    "#         --------\n",
    "#         mutual_information : np.array\n",
    "#             Взаимная информация (epistemic uncertainty)\n",
    "#         \"\"\"\n",
    "#         # Формула (19): M̂I(y*;ω|x*,D) = Ĥ(y*|x*,D) - E(Ĥ(y*|x*,ω))\n",
    "#         mutual_information = predictive_entropy - expected_entropy\n",
    "\n",
    "#         # MI не может быть отрицательной (ограничиваем снизу)\n",
    "#         mutual_information = np.maximum(mutual_information, 0)\n",
    "\n",
    "#         return mutual_information\n",
    "\n",
    "#     def generate_wang_dong_noise(self, ctr_predicted, T=50, dropout_rate=0.05,\n",
    "#                                 noise_type='total', scale_factor=1.0):\n",
    "#         \"\"\"\n",
    "#         Генерация шума по точной методологии Wang & Dong (2023)\n",
    "\n",
    "#         Parameters:\n",
    "#         -----------\n",
    "#         ctr_predicted : array-like\n",
    "#             Предсказанные значения CTR\n",
    "#         T : int\n",
    "#             Количество MC семплов (из статьи: обычно 50)\n",
    "#         dropout_rate : float\n",
    "#             Dropout rate (из статьи: обычно 0.05)\n",
    "#         noise_type : str\n",
    "#             'epistemic' - только epistemic uncertainty (MI)\n",
    "#             'aleatoric' - только aleatoric uncertainty (expected entropy)\n",
    "#             'total' - общая uncertainty (predictive entropy)\n",
    "#         scale_factor : float\n",
    "#             Масштабирующий коэффициент для шума\n",
    "\n",
    "#         Returns:\n",
    "#         --------\n",
    "#         noise : np.array\n",
    "#             Сгенерированный шум\n",
    "#         uncertainty_info : dict\n",
    "#             Детальная информация об uncertainty\n",
    "#         \"\"\"\n",
    "#         # Шаг 1: Генерируем MC предсказания (симуляция dropout)\n",
    "#         mc_predictions = self.monte_carlo_dropout_predictions(\n",
    "#             ctr_predicted, T=T, dropout_rate=dropout_rate\n",
    "#         )\n",
    "\n",
    "#         # Шаг 2: Вычисляем три типа uncertainty по формулам из статьи\n",
    "#         predictive_entropy = self.calculate_predictive_entropy(mc_predictions)\n",
    "#         expected_entropy = self.calculate_expected_entropy(mc_predictions)\n",
    "#         mutual_information = self.calculate_mutual_information(\n",
    "#             predictive_entropy, expected_entropy\n",
    "#         )\n",
    "\n",
    "#         # Шаг 3: Выбираем тип uncertainty для генерации шума\n",
    "#         if noise_type == 'epistemic':\n",
    "#             # Epistemic uncertainty = MI (неопределенность модели)\n",
    "#             uncertainty_values = mutual_information\n",
    "#         elif noise_type == 'aleatoric':\n",
    "#             # Aleatoric uncertainty = Expected entropy (неопределенность данных)\n",
    "#             uncertainty_values = expected_entropy\n",
    "#         elif noise_type == 'total':\n",
    "#             # Total uncertainty = Predictive entropy\n",
    "#             uncertainty_values = predictive_entropy\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unknown noise_type: {noise_type}\")\n",
    "\n",
    "#         # Шаг 4: Генерируем шум с дисперсией, пропорциональной uncertainty\n",
    "#         # Чем больше uncertainty, тем больше потенциальный шум\n",
    "#         noise_std = scale_factor * np.sqrt(uncertainty_values)\n",
    "#         noise = np.random.normal(0, noise_std)\n",
    "\n",
    "#         # Информация для анализа\n",
    "#         uncertainty_info = {\n",
    "#             'predictive_entropy': predictive_entropy,\n",
    "#             'expected_entropy': expected_entropy,\n",
    "#             'mutual_information': mutual_information,\n",
    "#             'noise_std': noise_std,\n",
    "#             'mc_predictions_std': np.std(mc_predictions, axis=0),\n",
    "#             'method_params': {\n",
    "#                 'T': T,\n",
    "#                 'dropout_rate': dropout_rate,\n",
    "#                 'noise_type': noise_type,\n",
    "#                 'scale_factor': scale_factor\n",
    "#             }\n",
    "#         }\n",
    "\n",
    "#         return noise, uncertainty_info\n",
    "\n",
    "#     def suggest_scale_factor(self, ctr_predicted, target_noise_std=0.05):\n",
    "#         \"\"\"\n",
    "#         Автоматический подбор scale_factor для достижения желаемого уровня шума\n",
    "\n",
    "#         Parameters:\n",
    "#         -----------\n",
    "#         ctr_predicted : array-like\n",
    "#             Предсказанные значения CTR\n",
    "#         target_noise_std : float\n",
    "#             Желаемое стандартное отклонение шума\n",
    "\n",
    "#         Returns:\n",
    "#         --------\n",
    "#         optimal_scale_factor : float\n",
    "#             Рекомендуемый scale_factor\n",
    "#         \"\"\"\n",
    "#         # Тестируем разные scale_factor\n",
    "#         test_scales = np.logspace(-2, 1, 20)  # от 0.01 до 10\n",
    "\n",
    "#         best_scale = 1.0\n",
    "#         min_diff = float('inf')\n",
    "\n",
    "#         for scale in test_scales:\n",
    "#             noise, _ = self.generate_wang_dong_noise(\n",
    "#                 ctr_predicted, scale_factor=scale, T=20  # Быстрая оценка\n",
    "#             )\n",
    "#             actual_std = np.std(noise)\n",
    "#             diff = abs(actual_std - target_noise_std)\n",
    "\n",
    "#             if diff < min_diff:\n",
    "#                 min_diff = diff\n",
    "#                 best_scale = scale\n",
    "\n",
    "#         return best_scale\n",
    "\n",
    "# # Основная функция для использования\n",
    "# def generate_wang_dong_2023_noise(ctr_values, target_noise_std=0.05,\n",
    "#                                  noise_type='total', auto_scale=True):\n",
    "#     \"\"\"\n",
    "#     Простая функция для генерации шума по Wang & Dong (2023)\n",
    "\n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     ctr_values : array-like\n",
    "#         Ваши предсказанные CTR значения\n",
    "#     target_noise_std : float\n",
    "#         Желаемое стандартное отклонение шума\n",
    "#     noise_type : str\n",
    "#         'epistemic', 'aleatoric', или 'total'\n",
    "#     auto_scale : bool\n",
    "#         Автоматически подобрать scale_factor\n",
    "\n",
    "#     Returns:\n",
    "#     --------\n",
    "#     noise : np.array\n",
    "#         Сгенерированный шум\n",
    "#     citation_info : str\n",
    "#         Готовый текст для цитирования в статье\n",
    "#     \"\"\"\n",
    "#     generator = WangDongCTRNoise(random_state=42)\n",
    "\n",
    "#     if auto_scale:\n",
    "#         scale_factor = generator.suggest_scale_factor(ctr_values, target_noise_std)\n",
    "#         # print(f\"Автоматически подобранный scale_factor: {scale_factor:.3f}\")\n",
    "#     else:\n",
    "#         scale_factor = 1.0\n",
    "\n",
    "#     noise, info = generator.generate_wang_dong_noise(\n",
    "#         ctr_values,\n",
    "#         noise_type=noise_type,\n",
    "#         scale_factor=scale_factor,\n",
    "#         T=50,  # Как в статье\n",
    "#         dropout_rate=0.05  # Оптимальное значение из статьи\n",
    "#     )\n",
    "\n",
    "#     return noise, _ # citation_info.strip()\n",
    "\n",
    "# # Пример использования\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Тестовые данные - ваши CTR значения\n",
    "#     np.random.seed(42)\n",
    "#     test_ctr = np.random.uniform(0.01, 0.3, 1000)\n",
    "\n",
    "#     print(\"=== Генерация шума по Wang & Dong (2023) ===\")\n",
    "#     noise, citation = generate_wang_dong_2023_noise(\n",
    "#         test_ctr,\n",
    "#         target_noise_std=0.05,\n",
    "#         noise_type='total'\n",
    "#     )\n",
    "\n",
    "#     print(\"\\n\" + \"=\"*50)\n",
    "#     print(\"ТЕКСТ ДЛЯ СТАТЬИ:\")\n",
    "#     print(\"=\"*50)\n",
    "#     print(citation)\n",
    "\n",
    "#     # Валидация\n",
    "#     generator = WangDongCTRNoise()\n",
    "#     # info = generator.validate_methodology(test_ctr, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "461e9c7a-faa3-4485-8ec3-52f0feb61649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_noised_stats_mse(stats_df, stats_save_path, old_ctr, eps, auction_mode, seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    grouped = stats_df.groupby('campaign_id')\n",
    "    for campaign_id, group in grouped:\n",
    "        old_ctr = group['CTRPredicts'].values\n",
    "\n",
    "        noise, citation = generate_wang_dong_2023_noise(\n",
    "            old_ctr,\n",
    "            target_noise_std=eps,\n",
    "            noise_type='total'\n",
    "        )\n",
    "\n",
    "        # noise = np.random.rand(old_ctr.size)\n",
    "        # noise = noise / np.linalg.norm(noise) * np.sqrt(2*eps)\n",
    "        stats_df.loc[stats_df.campaign_id == campaign_id, 'CTRPredicts_noised'] = np.clip(old_ctr + noise, 0.01, 0.1)\n",
    "\n",
    "    stats_df.to_csv(stats_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eea3c19-f756-4550-8c0f-ac3c593b39eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [15:47<00:00, 135.36s/it]\n"
     ]
    }
   ],
   "source": [
    "eps_set_data = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 1e-12]\n",
    "# eps_set_model = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 1e-12]\n",
    "\n",
    "bidder_types = ['simple', 'robust']\n",
    "seeds = list(range(10))\n",
    "\n",
    "metrics_list = []\n",
    "\n",
    "old_ctr = np.array(stats_df.CTRPredicts.copy())\n",
    "\n",
    "stats_save_path = f\"../data/data/{auction_mode.lower()}/stats_{auction_mode.lower()}_filtered_train_noised.csv\"\n",
    "\n",
    "for eps in tqdm(eps_set_data):\n",
    "    # for factor in [0.1, 1., 10, 100]:\n",
    "    # eps_data = eps_model # * factor\n",
    "    for seed in seeds:\n",
    "        # print(seed)\n",
    "        # Add noise to data\n",
    "        create_noised_stats_mse(stats_df, stats_save_path, old_ctr, eps, auction_mode, seed)\n",
    "\n",
    "        cpc = 300.\n",
    "\n",
    "        # Simple bid\n",
    "        res_simple = autobidder_check(\n",
    "            bidder=SimpleBid,\n",
    "            params={\"input_campaigns\": campaigns_path,\n",
    "                    \"input_stats\": stats_save_path,\n",
    "                    'eps': eps,\n",
    "                    'p': 1,\n",
    "                    'q': 1,\n",
    "                    'LP': True,\n",
    "                    'CPC': cpc},\n",
    "            loss_type=loss_type\n",
    "        )\n",
    "        metrics_list.append({\n",
    "            'eps': eps,\n",
    "            # 'eps_model': eps,\n",
    "            'bidder_type': 'simple',\n",
    "            'seed': seed,\n",
    "            'tvc': res_simple['score'][0],\n",
    "            'cpc_percent': res_simple['score'][1],\n",
    "            'cpc_avg': res_simple['score'][2]\n",
    "        })\n",
    "\n",
    "        # Robust bid\n",
    "        res_robust = autobidder_check(\n",
    "            bidder=RobustBidMSE,\n",
    "            params={\"input_campaigns\": campaigns_path,\n",
    "                    \"input_stats\": stats_save_path,\n",
    "                    'eps': eps,\n",
    "                    'gamma': 1.,\n",
    "                    'beta': 1.,\n",
    "                    'lambda_': 1.,\n",
    "                    'chi': 1.,\n",
    "                    'theta': 1.,\n",
    "                    'delta': 1.,\n",
    "                    'kappa': 1.,\n",
    "                    'LP': True,\n",
    "                    'CPC': cpc},\n",
    "            loss_type=loss_type\n",
    "        )\n",
    "\n",
    "        metrics_list.append({\n",
    "            'eps': eps,\n",
    "            # 'eps_model': eps_model,\n",
    "            'bidder_type': 'robust',\n",
    "            'seed': seed,\n",
    "            'tvc': res_robust['score'][0],\n",
    "            'cpc_percent': res_robust['score'][1],\n",
    "            'cpc_avg': res_robust['score'][2]\n",
    "        })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_list, columns=['eps', 'bidder_type', 'seed', 'tvc', 'cpc_percent', 'cpc_avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe40dc1d-e769-40b1-aac4-f9f450682ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eps</th>\n",
       "      <th>bidder_type</th>\n",
       "      <th>mean_tvc</th>\n",
       "      <th>std_tvc</th>\n",
       "      <th>mean_cpc_percent</th>\n",
       "      <th>std_cpc_percent</th>\n",
       "      <th>mean_cpc_avg</th>\n",
       "      <th>std_cpc_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>robust</td>\n",
       "      <td>2.260368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.064523</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>simple</td>\n",
       "      <td>2.260151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.108536</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.000000e-04</td>\n",
       "      <td>robust</td>\n",
       "      <td>2.787040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>331.573948</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.000000e-04</td>\n",
       "      <td>simple</td>\n",
       "      <td>2.260151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.108536</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>robust</td>\n",
       "      <td>3.072124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>312.071788</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>simple</td>\n",
       "      <td>2.260151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.108536</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.000000e-03</td>\n",
       "      <td>robust</td>\n",
       "      <td>3.407976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>291.231927</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.000000e-03</td>\n",
       "      <td>simple</td>\n",
       "      <td>2.251925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>469.767519</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>robust</td>\n",
       "      <td>3.546123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.363859</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>simple</td>\n",
       "      <td>2.172647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>474.291485</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.000000e-02</td>\n",
       "      <td>robust</td>\n",
       "      <td>3.948277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275.151341</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.000000e-02</td>\n",
       "      <td>simple</td>\n",
       "      <td>2.074633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>528.333104</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>robust</td>\n",
       "      <td>3.953850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.584078</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>simple</td>\n",
       "      <td>2.091708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>545.335596</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             eps bidder_type  mean_tvc  std_tvc  mean_cpc_percent  \\\n",
       "0   1.000000e-12      robust  2.260368      0.0               0.0   \n",
       "1   1.000000e-12      simple  2.260151      0.0               0.0   \n",
       "2   5.000000e-04      robust  2.787040      0.0               0.0   \n",
       "3   5.000000e-04      simple  2.260151      0.0               0.0   \n",
       "4   1.000000e-03      robust  3.072124      0.0               0.0   \n",
       "5   1.000000e-03      simple  2.260151      0.0               0.0   \n",
       "6   5.000000e-03      robust  3.407976      0.0               0.0   \n",
       "7   5.000000e-03      simple  2.251925      0.0               0.0   \n",
       "8   1.000000e-02      robust  3.546123      0.0               0.0   \n",
       "9   1.000000e-02      simple  2.172647      0.0               0.0   \n",
       "10  5.000000e-02      robust  3.948277      0.0               0.0   \n",
       "11  5.000000e-02      simple  2.074633      0.0               0.0   \n",
       "12  1.000000e-01      robust  3.953850      0.0               0.0   \n",
       "13  1.000000e-01      simple  2.091708      0.0               0.0   \n",
       "\n",
       "    std_cpc_percent  mean_cpc_avg  std_cpc_avg  \n",
       "0               0.0    468.064523          0.0  \n",
       "1               0.0    468.108536          0.0  \n",
       "2               0.0    331.573948          0.0  \n",
       "3               0.0    468.108536          0.0  \n",
       "4               0.0    312.071788          0.0  \n",
       "5               0.0    468.108536          0.0  \n",
       "6               0.0    291.231927          0.0  \n",
       "7               0.0    469.767519          0.0  \n",
       "8               0.0    282.363859          0.0  \n",
       "9               0.0    474.291485          0.0  \n",
       "10              0.0    275.151341          0.0  \n",
       "11              0.0    528.333104          0.0  \n",
       "12              0.0    280.584078          0.0  \n",
       "13              0.0    545.335596          0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_metrics = metrics_df.groupby(['eps', 'bidder_type']).agg(\n",
    "    mean_tvc=('tvc', 'mean'),\n",
    "    std_tvc=('tvc', 'std'),\n",
    "    mean_cpc_percent=('cpc_percent', 'mean'),\n",
    "    std_cpc_percent=('cpc_percent', 'std'),\n",
    "    mean_cpc_avg=('cpc_avg', 'mean'),\n",
    "    std_cpc_avg=('cpc_avg', 'std')\n",
    ").reset_index()\n",
    "\n",
    "agg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b075f016-b6a5-4649-b37c-13a28686b356",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_metrics.to_csv(f'../results/metrics_{loss_type.lower()}_BAT_CTR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dd77930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a62fa2f7",
   "metadata": {},
   "source": [
    "### TVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea1081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tvc_simple_ctr = np.array(agg_metrics[agg_metrics.bidder_type == 'simple'].mean_tvc)\n",
    "mean_tvc_robust_ctr = np.array(agg_metrics[agg_metrics.bidder_type == 'robust'].mean_tvc)\n",
    "\n",
    "# results from another notebook with normal noise\n",
    "mean_tvc_simple_norm = np.array([2.26495932, 2.26782824, 2.19687101, 2.08576958, 2.05811226,\n",
    "       1.93404816, 1.89193563])\n",
    "mean_tvc_robust_norm = np.array([2.26483722, 2.79915243, 3.03667371, 3.34679585, 3.48146273,\n",
    "       3.91136865, 4.0522365 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1035f44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.00009584, 1.23312083, 1.35925602, 1.51516363, 1.63840515,\n",
       "        1.94609533, 1.93573035]),\n",
       " array([0.99994609, 1.23428767, 1.38227219, 1.60458561, 1.69158058,\n",
       "        2.02237397, 2.14184692]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_tvc_robust_ctr / mean_tvc_simple_ctr), (mean_tvc_robust_norm / mean_tvc_simple_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "832e8f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.5182667368113836, 1.5824132896383467)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_tvc_robust_ctr / mean_tvc_simple_ctr).mean(), (mean_tvc_robust_norm / mean_tvc_simple_norm).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e70b9f",
   "metadata": {},
   "source": [
    "### CPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9b9081",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_cpc_simple_ctr = np.array(agg_metrics[agg_metrics.bidder_type == 'simple'].mean_cpc_avg)\n",
    "mean_cpc_robust_ctr = np.array(agg_metrics[agg_metrics.bidder_type == 'robust'].mean_cpc_avg)\n",
    "\n",
    "# results from another notebook with normal noise\n",
    "mean_cpc_simple_norm = np.array([515.13199505, 514.81091864, 518.49015618, 523.06691103,\n",
    "       524.31452656, 525.98242848, 525.52466516])\n",
    "mean_cpc_robust_norm = np.array([515.05495171, 361.7245655 , 339.32337875, 316.72874209,\n",
    "       306.37696331, 273.53070906, 256.42070281])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c2a6a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.99989679, 0.69479282, 0.65160455, 0.60698901, 0.57981732,\n",
       "        0.49342042, 0.46011147]),\n",
       " array([0.99985044, 0.70263577, 0.65444517, 0.60552242, 0.58433812,\n",
       "        0.52003773, 0.48793276]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_cpc_robust_ctr / mean_cpc_simple_ctr), (mean_cpc_robust_norm / mean_cpc_simple_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b72eeedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6409474830510654, 0.6506803447485854)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_cpc_robust_ctr / mean_cpc_simple_ctr).mean(), (mean_cpc_robust_norm / mean_cpc_simple_norm).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1978e674-efbd-456e-afd0-f0039e8b9e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_with_error_CTR(\n",
    "    eps_set=eps_set,\n",
    "    agg_metrics=agg_metrics,\n",
    "    metric_mean_col='mean_tvc',\n",
    "    metric_std_col='std_tvc',\n",
    "    metric_name='TVC',\n",
    "    y_label='Total Value Clicks',\n",
    "    loss_type=loss_type\n",
    ")\n",
    "\n",
    "plot_metric_with_error_CTR(\n",
    "    eps_set=eps_set,\n",
    "    agg_metrics=agg_metrics,\n",
    "    metric_mean_col='mean_cpc_percent',\n",
    "    metric_std_col='std_cpc_percent',\n",
    "    metric_name='CPC Percent',\n",
    "    y_label='Cost per Click (%)',\n",
    "    loss_type=loss_type\n",
    ")\n",
    "\n",
    "plot_metric_with_error_CTR(\n",
    "    eps_set=eps_set,\n",
    "    agg_metrics=agg_metrics,\n",
    "    metric_mean_col='mean_cpc_avg',\n",
    "    metric_std_col='std_cpc_avg',\n",
    "    metric_name='CPC Avg',\n",
    "    y_label='Average Cost per Click',\n",
    "    loss_type=loss_type\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b89e833-93ad-4515-8170-702745803f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
